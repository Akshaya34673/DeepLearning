{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2671adc-c944-42e1-8a67-4d6b0075d1ec",
   "metadata": {
    "id": "c2671adc-c944-42e1-8a67-4d6b0075d1ec"
   },
   "source": [
    "# Step 1   Define Dataset (3 Features, 1 Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538a15d8-9509-40b6-9fc5-d033d57da2d6",
   "metadata": {
    "id": "538a15d8-9509-40b6-9fc5-d033d57da2d6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1ï¸âƒ£ Define Dataset (3 Features, 1 Label)\n",
    "X = np.array([[90, 85, 80],  # Pass\n",
    "              [70, 60, 50],  # Fail\n",
    "              [85, 75, 70],  # Pass\n",
    "              [60, 55, 45],  # Fail\n",
    "              [95, 90, 88]]) # Pass\n",
    "\n",
    "y = np.array([[1], [0], [1], [0], [1]])  # Labels (1 = Pass, 0 = Fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf389ee-5202-4e3e-bc28-3e132e92329d",
   "metadata": {
    "id": "fbf389ee-5202-4e3e-bc28-3e132e92329d"
   },
   "source": [
    "# Step 2 Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5288498-cd01-40d4-9e44-57e2b2238167",
   "metadata": {
    "id": "e5288498-cd01-40d4-9e44-57e2b2238167"
   },
   "outputs": [],
   "source": [
    "# Normalize the dataset (Feature Scaling)\n",
    "X = X / 100.0  # Scale values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ec8c54-6980-4fc7-8179-1b4a5d724d46",
   "metadata": {
    "id": "97ec8c54-6980-4fc7-8179-1b4a5d724d46"
   },
   "outputs": [],
   "source": [
    "# ðŸ”¹ Split into Train and Test Sets (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbd56-60e2-4670-8506-cd22e325324e",
   "metadata": {
    "id": "5e4dbd56-60e2-4670-8506-cd22e325324e"
   },
   "source": [
    "# Step 3 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb329aef-4a9b-4e63-942a-acc6e5853bd7",
   "metadata": {
    "id": "bb329aef-4a9b-4e63-942a-acc6e5853bd7"
   },
   "source": [
    "## Task 1 Initialize Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6c5c32-5c51-4e8a-975a-f9d470654a0f",
   "metadata": {
    "id": "4b6c5c32-5c51-4e8a-975a-f9d470654a0f"
   },
   "outputs": [],
   "source": [
    "# Initialize Weights and Biases\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(3, 1)  # Weights for Hidden Layer (3 inputs -> 1 neuron)\n",
    "b1 = np.random.randn(1)     # Bias for Hidden Layer\n",
    "\n",
    "W2 = np.random.randn(1, 1)  # Weights for Output Layer (1 neuron -> 1 output)\n",
    "b2 = np.random.randn(1)     # Bias for Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085676a2-b1f0-4570-bd0a-b4fa2f335d78",
   "metadata": {
    "id": "085676a2-b1f0-4570-bd0a-b4fa2f335d78"
   },
   "source": [
    "## Task 2 Define Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4dffe7-3515-4157-b2c8-dc4f9a35ea4f",
   "metadata": {
    "id": "aa4dffe7-3515-4157-b2c8-dc4f9a35ea4f"
   },
   "outputs": [],
   "source": [
    "#  Define Activation Functions\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)  # ReLU Activation\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))  # Sigmoid Activation\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cdacf8-2476-4759-91fe-748e677d84cf",
   "metadata": {
    "id": "f6cdacf8-2476-4759-91fe-748e677d84cf"
   },
   "source": [
    "## Task 3 Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e913b08e-8385-4db2-8d8d-1def77bcf6af",
   "metadata": {
    "id": "e913b08e-8385-4db2-8d8d-1def77bcf6af"
   },
   "outputs": [],
   "source": [
    "#  Define Training Parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b4c34-f1d9-4f29-92cf-431390266f0f",
   "metadata": {
    "id": "bb4b4c34-f1d9-4f29-92cf-431390266f0f"
   },
   "source": [
    "## Task 4  Forward and back ward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2724884-a085-4684-b410-04a53ccff37d",
   "metadata": {
    "id": "e2724884-a085-4684-b410-04a53ccff37d",
    "outputId": "fc3d6d55-bde5-49c7-ed78-87834e5f391b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9724\n",
      "Epoch 100, Loss: 0.5570\n",
      "Epoch 200, Loss: 0.5314\n",
      "Epoch 300, Loss: 0.5279\n",
      "Epoch 400, Loss: 0.5258\n",
      "Epoch 500, Loss: 0.5239\n",
      "Epoch 600, Loss: 0.5218\n",
      "Epoch 700, Loss: 0.5198\n",
      "Epoch 800, Loss: 0.5176\n",
      "Epoch 900, Loss: 0.5154\n"
     ]
    }
   ],
   "source": [
    "#  Train the MLP on Training Data\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    Z1 = np.dot(X_train, W1) + b1  # Hidden Layer Linear\n",
    "    A1 = relu(Z1)                  # Apply ReLU Activation\n",
    "\n",
    "    Z2 = np.dot(A1, W2) + b2        # Output Layer Linear\n",
    "    A2 = sigmoid(Z2)                # Apply Sigmoid Activation\n",
    "\n",
    "    # Compute Binary Cross-Entropy Loss\n",
    "    loss = -np.mean(y_train * np.log(A2) + (1 - y_train) * np.log(1 - A2))\n",
    "\n",
    "    # Backpropagation (Gradient Descent)\n",
    "    dZ2 = A2 - y_train  # Derivative of Sigmoid\n",
    "    dW2 = np.dot(A1.T, dZ2) / len(X_train)\n",
    "    db2 = np.sum(dZ2) / len(X_train)\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)  # Derivative of ReLU\n",
    "    dW1 = np.dot(X_train.T, dZ1) / len(X_train)\n",
    "    db1 = np.sum(dZ1) / len(X_train)\n",
    "\n",
    "    # Update Weights and Biases\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ae0c3-ac9a-46f9-996c-5a5a203c23f5",
   "metadata": {
    "id": "cd7ae0c3-ac9a-46f9-996c-5a5a203c23f5"
   },
   "source": [
    "# Step 4  Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa167b11-5274-44ad-85a0-b93209ef0792",
   "metadata": {
    "id": "aa167b11-5274-44ad-85a0-b93209ef0792",
    "outputId": "dff2c841-5207-41a6-94a6-0e0e4122347d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Predictions: [1 1 1 1]\n",
      "Final Testing Predictions: [1]\n"
     ]
    }
   ],
   "source": [
    "# Prediction Function\n",
    "def predict(X_test):\n",
    "    Z1 = np.dot(X_test, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return (A2 > 0.5).astype(int)  # Convert probability to Pass/Fail (1/0)\n",
    "\n",
    "# ðŸ”¹ Evaluate on Training and Test Data\n",
    "train_predictions = predict(X_train)\n",
    "test_predictions = predict(X_test)\n",
    "\n",
    "print(\"\\nFinal Training Predictions:\", train_predictions.flatten())\n",
    "print(\"Final Testing Predictions:\", test_predictions.flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e56ca-5ef5-49ba-b58e-6cad0f7fb8d4",
   "metadata": {
    "id": "d10e56ca-5ef5-49ba-b58e-6cad0f7fb8d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8088318-7f52-42b9-bcc1-72561d390225",
   "metadata": {
    "id": "a8088318-7f52-42b9-bcc1-72561d390225"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d03a6-ef7c-4a57-967a-59d34bfc7bdc",
   "metadata": {
    "id": "769d03a6-ef7c-4a57-967a-59d34bfc7bdc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe075bb-3bfa-4b91-b284-7841f4be0ae6",
   "metadata": {
    "id": "bfe075bb-3bfa-4b91-b284-7841f4be0ae6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abc658-5729-4e0d-8144-68b0de2a8cc8",
   "metadata": {
    "id": "74abc658-5729-4e0d-8144-68b0de2a8cc8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358b8b4-4fb6-493f-8c68-162cf8bd8645",
   "metadata": {
    "id": "d358b8b4-4fb6-493f-8c68-162cf8bd8645"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
